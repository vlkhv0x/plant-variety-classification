"""
–ú–æ–¥—É–ª—å —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–µ–º—è–Ω
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.applications import ResNet50, EfficientNetB0, VGG16
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau


class SeedClassificationModel:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–µ–º—è–Ω
    """
    
    def __init__(self, num_classes, img_size=(224, 224), model_type='resnet50'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        
        Args:
            num_classes: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
            img_size: —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            model_type: —Ç–∏–ø –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ ('resnet50', 'efficientnet', 'vgg16')
        """
        self.num_classes = num_classes
        self.img_size = img_size
        self.model_type = model_type
        self.model = None
        
    def build_model(self, trainable_base=False):
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å transfer learning
        
        Args:
            trainable_base: –¥–µ–ª–∞—Ç—å –ª–∏ –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å trainable
            
        Returns:
            model: —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Keras
        """
        input_shape = (*self.img_size, 3)
        
        # –í—ã–±–æ—Ä –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        if self.model_type == 'resnet50':
            base_model = ResNet50(
                weights='imagenet',
                include_top=False,
                input_shape=input_shape
            )
        elif self.model_type == 'efficientnet':
            base_model = EfficientNetB0(
                weights='imagenet',
                include_top=False,
                input_shape=input_shape
            )
        elif self.model_type == 'vgg16':
            base_model = VGG16(
                weights='imagenet',
                include_top=False,
                input_shape=input_shape
            )
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏: {self.model_type}")
        
        # –ó–∞–º–æ—Ä–æ–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        base_model.trainable = trainable_base
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –º–æ–¥–µ–ª–∏
        inputs = keras.Input(shape=input_shape)
        
        # –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
        x = base_model(inputs, training=False)
        
        # Global Average Pooling
        x = layers.GlobalAveragePooling2D()(x)
        
        # Dense layers
        x = layers.Dense(512, activation='relu')(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(0.5)(x)
        
        x = layers.Dense(256, activation='relu')(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(0.3)(x)
        
        # Output layer
        outputs = layers.Dense(self.num_classes, activation='softmax')(x)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model = keras.Model(inputs=inputs, outputs=outputs)
        
        self.model = model
        return model
    
    def compile_model(self, learning_rate=0.0001):
        """
        –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏
        
        Args:
            learning_rate: learning rate –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
        """
        if self.model is None:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å—é build_model()")
        
        self.model.compile(
            optimizer=Adam(learning_rate=learning_rate),
            loss='categorical_crossentropy',
            metrics=[
                'accuracy',
                keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy'),
                keras.metrics.Precision(name='precision'),
                keras.metrics.Recall(name='recall')
            ]
        )
        
        print("‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–∞")
        
    def get_callbacks(self, checkpoint_path='models/best_model.h5'):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ callbacks –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            checkpoint_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            
        Returns:
            —Å–ø–∏—Å–æ–∫ callbacks
        """
        callbacks = [
            # Early Stopping
            EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True,
                verbose=1
            ),
            
            # Model Checkpoint
            ModelCheckpoint(
                filepath=checkpoint_path,
                monitor='val_accuracy',
                save_best_only=True,
                verbose=1
            ),
            
            # Reduce Learning Rate
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7,
                verbose=1
            )
        ]
        
        return callbacks
    
    def train(self, train_generator, val_generator, epochs=50, callbacks=None):
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        
        Args:
            train_generator: –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            val_generator: –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            epochs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            callbacks: —Å–ø–∏—Å–æ–∫ callbacks
            
        Returns:
            history: –∏—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        """
        if self.model is None:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –∏ —Å–∫–æ–º–ø–∏–ª–∏—Ä—É–π—Ç–µ –º–æ–¥–µ–ª—å")
        
        if callbacks is None:
            callbacks = self.get_callbacks()
        
        print(f"\nüöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ {self.model_type}...")
        print(f"–≠–ø–æ—Ö–∏: {epochs}")
        print(f"Train batches: {len(train_generator)}")
        print(f"Val batches: {len(val_generator)}")
        
        history = self.model.fit(
            train_generator,
            validation_data=val_generator,
            epochs=epochs,
            callbacks=callbacks,
            verbose=1
        )
        
        print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        
        return history
    
    def fine_tune(self, train_generator, val_generator, epochs=20, 
                  unfreeze_layers=50, learning_rate=1e-5):
        """
        Fine-tuning –º–æ–¥–µ–ª–∏ (—Ä–∞–∑–º–æ—Ä–æ–∑–∫–∞ —á–∞—Å—Ç–∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏)
        
        Args:
            train_generator: –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            val_generator: –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            epochs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö fine-tuning
            unfreeze_layers: —Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–ª–æ—ë–≤ —Ä–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å
            learning_rate: learning rate –¥–ª—è fine-tuning
            
        Returns:
            history: –∏—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        """
        print(f"\nüîß Fine-tuning: —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ {unfreeze_layers} —Å–ª–æ—ë–≤")
        
        # –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–ª–æ–∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        base_model = self.model.layers[1]  # –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å - –≤—Ç–æ—Ä–æ–π —Å–ª–æ–π
        base_model.trainable = True
        
        # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –≤—Å–µ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö unfreeze_layers
        for layer in base_model.layers[:-unfreeze_layers]:
            layer.trainable = False
        
        # –ü–µ—Ä–µ–∫–æ–º–ø–∏–ª—è—Ü–∏—è —Å –º–µ–Ω—å—à–∏–º learning rate
        self.model.compile(
            optimizer=Adam(learning_rate=learning_rate),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # –û–±—É—á–µ–Ω–∏–µ
        history = self.model.fit(
            train_generator,
            validation_data=val_generator,
            epochs=epochs,
            callbacks=self.get_callbacks(checkpoint_path='models/finetuned_model.h5'),
            verbose=1
        )
        
        print("\n‚úÖ Fine-tuning –∑–∞–≤–µ—Ä—à—ë–Ω!")
        
        return history
    
    def summary(self):
        """–í—ã–≤–æ–¥ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏"""
        if self.model is None:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –º–æ–¥–µ–ª—å")
        return self.model.summary()
    
    def save_model(self, filepath='models/final_model.h5'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")
        self.model.save(filepath)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {filepath}")
    
    @staticmethod
    def load_model(filepath):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        return keras.models.load_model(filepath)


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    num_classes = 10
    
    model_builder = SeedClassificationModel(
        num_classes=num_classes,
        img_size=(224, 224),
        model_type='resnet50'
    )
    
    model = model_builder.build_model()
    model_builder.compile_model()
    
    print("\nüìä –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:")
    model_builder.summary()
