"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞ —Å–µ–º—è–Ω –Ω–∞ –Ω–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
"""

import os
import argparse
import json
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
from PIL import Image
import tensorflow as tf
from tensorflow import keras

from data_preprocessing import load_and_preprocess_image


def parse_args():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(description='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ —Å–µ–º—è–Ω')
    
    parser.add_argument('--image_path', type=str, required=True,
                        help='–ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é')
    parser.add_argument('--model_path', type=str, default='models/best_model.h5',
                        help='–ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏')
    parser.add_argument('--config_path', type=str, default='models/config.json',
                        help='–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--top_k', type=int, default=3,
                        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π')
    parser.add_argument('--show_image', action='store_true',
                        help='–ü–æ–∫–∞–∑–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º')
    
    return parser.parse_args()


def load_config(config_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏"""
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {config_path}")
    
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    return config


def predict_image(model, image_path, class_names, img_size=(224, 224), top_k=3):
    """
    –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    
    Args:
        model: –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        image_path: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        class_names: —Å–ø–∏—Å–æ–∫ –∏–º—ë–Ω –∫–ª–∞—Å—Å–æ–≤
        img_size: —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        top_k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        
    Returns:
        predictions: —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    """
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    img = load_and_preprocess_image(image_path, img_size)
    img_batch = np.expand_dims(img, axis=0)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    predictions = model.predict(img_batch, verbose=0)[0]
    
    # –¢–æ–ø-k –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    top_indices = np.argsort(predictions)[-top_k:][::-1]
    top_classes = [class_names[i] for i in top_indices]
    top_probs = [predictions[i] for i in top_indices]
    
    results = {
        'top_classes': top_classes,
        'top_probabilities': [float(p) for p in top_probs],
        'all_predictions': {class_names[i]: float(predictions[i]) 
                           for i in range(len(class_names))}
    }
    
    return results, img


def visualize_prediction(image, predictions, save_path=None):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
    
    Args:
        image: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (numpy array)
        predictions: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        save_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ None - –ø–æ–∫–∞–∑–∞—Ç—å)
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    ax1.imshow(image)
    ax1.axis('off')
    ax1.set_title('–í—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', fontsize=14, fontweight='bold')
    
    # –¢–æ–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    top_classes = predictions['top_classes']
    top_probs = predictions['top_probabilities']
    
    y_pos = np.arange(len(top_classes))
    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_classes)))
    
    bars = ax2.barh(y_pos, top_probs, color=colors)
    ax2.set_yticks(y_pos)
    ax2.set_yticklabels(top_classes)
    ax2.invert_yaxis()
    ax2.set_xlabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å', fontsize=12)
    ax2.set_title('–¢–æ–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π', fontsize=14, fontweight='bold')
    ax2.set_xlim(0, 1)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –±–∞—Ä—ã
    for i, (bar, prob) in enumerate(zip(bars, top_probs)):
        ax2.text(prob + 0.02, i, f'{prob:.2%}', 
                va='center', fontsize=10, fontweight='bold')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path}")
    else:
        plt.show()
    
    plt.close()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
    
    args = parse_args()
    
    print("=" * 70)
    print("üîÆ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –ö–õ–ê–°–°–ê –°–ï–ú–Ø–ù")
    print("=" * 70)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if not os.path.exists(args.image_path):
        raise FileNotFoundError(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {args.image_path}")
    
    print(f"\nüì∑ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {args.image_path}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    print(f"\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {args.config_path}")
    config = load_config(args.config_path)
    class_names = config['class_names']
    img_size = config.get('img_size', 224)
    
    print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(class_names)} –∫–ª–∞—Å—Å–æ–≤")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    print(f"\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {args.model_path}")
    if not os.path.exists(args.model_path):
        raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {args.model_path}")
    
    model = keras.models.load_model(args.model_path)
    print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    print(f"\nüîÆ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (top-{args.top_k})...")
    predictions, image = predict_image(
        model, 
        args.image_path, 
        class_names,
        img_size=(img_size, img_size),
        top_k=args.top_k
    )
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n" + "=" * 70)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø")
    print("=" * 70)
    
    print(f"\nü•á –¢–æ–ø-{args.top_k} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
    for i, (class_name, prob) in enumerate(zip(predictions['top_classes'], 
                                               predictions['top_probabilities']), 1):
        print(f"   {i}. {class_name:<20} - {prob:.2%}")
    
    print(f"\nüéØ –õ—É—á—à–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:")
    best_class = predictions['top_classes'][0]
    best_prob = predictions['top_probabilities'][0]
    print(f"   –ö–ª–∞—Å—Å: {best_class}")
    print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {best_prob:.2%}")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    if args.show_image:
        print("\nüìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        save_path = f"reports/prediction_{Path(args.image_path).stem}.png"
        visualize_prediction(image, predictions, save_path=save_path)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON
    output_path = f"reports/prediction_{Path(args.image_path).stem}.json"
    with open(output_path, 'w') as f:
        json.dump({
            'image_path': args.image_path,
            'predictions': predictions
        }, f, indent=4)
    
    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_path}")
    
    print("\n" + "=" * 70)


if __name__ == "__main__":
    main()
