"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–µ–º—è–Ω
"""

import os
import argparse
import json
from pathlib import Path
import tensorflow as tf

from data_preprocessing import SeedDataPreprocessor
from model import SeedClassificationModel
from utils import plot_training_history, create_directories


def parse_args():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(description='–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–µ–º—è–Ω')
    
    parser.add_argument('--data_dir', type=str, default='data/raw/seeds',
                        help='–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –¥–∞–Ω–Ω—ã–º–∏')
    parser.add_argument('--epochs', type=int, default=50,
                        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--batch_size', type=int, default=32,
                        help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞')
    parser.add_argument('--img_size', type=int, default=224,
                        help='–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è')
    parser.add_argument('--learning_rate', type=float, default=0.0001,
                        help='Learning rate')
    parser.add_argument('--model_type', type=str, default='resnet50',
                        choices=['resnet50', 'efficientnet', 'vgg16'],
                        help='–¢–∏–ø –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏')
    parser.add_argument('--fine_tune', action='store_true',
                        help='–í—ã–ø–æ–ª–Ω–∏—Ç—å fine-tuning –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--fine_tune_epochs', type=int, default=20,
                        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –¥–ª—è fine-tuning')
    
    return parser.parse_args()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"""
    
    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    args = parse_args()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    create_directories()
    
    print("=" * 70)
    print("üå± –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –°–û–†–¢–û–í –†–ê–°–¢–ï–ù–ò–ô")
    print("=" * 70)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
    print("\nüñ•Ô∏è  –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU:")
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ GPU: {len(gpus)}")
        for gpu in gpus:
            print(f"   - {gpu}")
    else:
        print("‚ö†Ô∏è  GPU –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
    
    # ========== 1. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• ==========
    print("\n" + "=" * 70)
    print("üìä –®–ê–ì 1: –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•")
    print("=" * 70)
    
    preprocessor = SeedDataPreprocessor(
        data_dir=args.data_dir,
        img_size=(args.img_size, args.img_size),
        batch_size=args.batch_size
    )
    
    train_gen, val_gen, test_gen = preprocessor.prepare_data_pipeline()
    
    num_classes = len(train_gen.class_indices)
    print(f"\n‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: {num_classes} –∫–ª–∞—Å—Å–æ–≤")
    
    # ========== 2. –°–û–ó–î–ê–ù–ò–ï –ú–û–î–ï–õ–ò ==========
    print("\n" + "=" * 70)
    print("üèóÔ∏è  –®–ê–ì 2: –°–û–ó–î–ê–ù–ò–ï –ú–û–î–ï–õ–ò")
    print("=" * 70)
    
    model_builder = SeedClassificationModel(
        num_classes=num_classes,
        img_size=(args.img_size, args.img_size),
        model_type=args.model_type
    )
    
    model = model_builder.build_model(trainable_base=False)
    model_builder.compile_model(learning_rate=args.learning_rate)
    
    print(f"\n‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞: {args.model_type}")
    print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: {model.count_params():,}")
    
    # ========== 3. –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò ==========
    print("\n" + "=" * 70)
    print("üöÄ –®–ê–ì 3: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
    print("=" * 70)
    
    history = model_builder.train(
        train_generator=train_gen,
        val_generator=val_gen,
        epochs=args.epochs
    )
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è
    history_dict = history.history
    with open('reports/training_history.json', 'w') as f:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy –≤ list –¥–ª—è JSON
        history_json = {k: [float(v) for v in vals] for k, vals in history_dict.items()}
        json.dump(history_json, f, indent=4)
    
    print("\n‚úÖ –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ reports/training_history.json")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è
    plot_training_history(history, save_path='reports/training_history.png')
    
    # ========== 4. FINE-TUNING (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ==========
    if args.fine_tune:
        print("\n" + "=" * 70)
        print("üîß –®–ê–ì 4: FINE-TUNING –ú–û–î–ï–õ–ò")
        print("=" * 70)
        
        fine_tune_history = model_builder.fine_tune(
            train_generator=train_gen,
            val_generator=val_gen,
            epochs=args.fine_tune_epochs,
            unfreeze_layers=50,
            learning_rate=args.learning_rate / 10
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ fine-tuning
        with open('reports/fine_tune_history.json', 'w') as f:
            history_json = {k: [float(v) for v in vals] 
                          for k, vals in fine_tune_history.history.items()}
            json.dump(history_json, f, indent=4)
        
        plot_training_history(fine_tune_history, 
                            save_path='reports/fine_tune_history.png')
    
    # ========== 5. –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò ==========
    print("\n" + "=" * 70)
    print("üíæ –®–ê–ì 5: –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
    print("=" * 70)
    
    model_builder.save_model('models/final_model.h5')
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = {
        'model_type': args.model_type,
        'num_classes': num_classes,
        'img_size': args.img_size,
        'batch_size': args.batch_size,
        'epochs': args.epochs,
        'learning_rate': args.learning_rate,
        'class_names': list(train_gen.class_indices.keys())
    }
    
    with open('models/config.json', 'w') as f:
        json.dump(config, f, indent=4)
    
    print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/config.json")
    
    # ========== –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–Å–¢ ==========
    print("\n" + "=" * 70)
    print("üìä –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print("=" * 70)
    
    # –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    best_val_acc = max(history.history['val_accuracy'])
    best_val_loss = min(history.history['val_loss'])
    
    print(f"\nüìà –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
    print(f"   - Accuracy: {best_val_acc:.4f}")
    print(f"   - Loss: {best_val_loss:.4f}")
    
    print(f"\nüìÅ –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    print(f"   - models/best_model.h5")
    print(f"   - models/final_model.h5")
    print(f"   - models/config.json")
    print(f"   - reports/training_history.json")
    print(f"   - reports/training_history.png")
    
    print("\nüéØ –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –∑–∞–ø—É—Å—Ç–∏—Ç–µ evaluate.py –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ")
    print("=" * 70)


if __name__ == "__main__":
    main()
